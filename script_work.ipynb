{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport modules.dataset_auxiliary, modules.classification_auxiliary, modules.ml_auxiliary, modules.bullets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import tensorly as tl\n",
    "from tensorly import random\n",
    "import os\n",
    "import pickle\n",
    "# import modules.dataset_auxiliary as daux\n",
    "# from modules.dataset_auxiliary import *\n",
    "# from modules.classification_auxiliary import *\n",
    "# from modules.ml_auxiliary import *\n",
    "from modules.bullets import*\n",
    "from modules.classification_auxiliary import *\n",
    "from modules.ml_auxiliary import *\n",
    "import copy\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "import json\n",
    "import timeit\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import xgboost as xgb\n",
    "import pystmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_type': 'LogReg', 'params': {}}\n"
     ]
    }
   ],
   "source": [
    "with open('/home/s.gostilovich/gesture_progect/gesture_classification/stages/models/model1.json', 'r') as f:\n",
    "    a = json.load(f)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.745169984991662"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit('mod.get_params()', number=100000, globals=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mpardir(input_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m a[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "a = os.path.pardir(input_path)\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.npz'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = os.path.splitext(input_path)\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pathlib.Path(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skgest-mpipe-center.npz'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/mnt/volume-1/04.skgest-bench/input/skgest-mpipe-center', '')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/mnt/volume-1/04.skgest-bench/input/skgest-mpipe-center.npz\"\n",
    "data = load_data(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor, data_tensor_test = data['x_train'], data['x_test']\n",
    "y_train, y_test = data['y_train'], data['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogReg(max_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LogReg',\n",
       " 'do_scaler': True,\n",
       " 'n_trials': 10,\n",
       " 'params': {'max_iter': 1}}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662466131.6106195"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120, 225)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor_test[0:1,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LogReg is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.gostilovich/gesture_progect/gesture_classification/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.295163154602051 s passed\n",
      "Inference time evaluation for mocel LogReg... n_timeit=1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m LogReg(max_iter\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mfit(data_tensor, y_train)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49meval_inference_time(data_tensor_test, \u001b[39m1000\u001b[39;49m)\n",
      "\u001b[1;32m/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb Cell 12\u001b[0m in \u001b[0;36mModelAbstract.eval_inference_time\u001b[0;34m(self, X, n_timeit)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=116'>117</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39m# model = self\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=119'>120</a>\u001b[0m total_time \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39;49mtimeit(\u001b[39m'\u001b[39;49m\u001b[39mself.model.predict(X)\u001b[39;49m\u001b[39m'\u001b[39;49m, number\u001b[39m=\u001b[39;49mn_timeit, \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m())\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=120'>121</a>\u001b[0m inference_time \u001b[39m=\u001b[39m total_time\u001b[39m/\u001b[39mn_timeit\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/gesture_progect/gesture_classification/script_work.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInference time for nodel \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m1000\u001b[39m\u001b[39m*\u001b[39minference_time\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m ms\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/timeit.py:233\u001b[0m, in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtimeit\u001b[39m(stmt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpass\u001b[39m\u001b[39m\"\u001b[39m, setup\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpass\u001b[39m\u001b[39m\"\u001b[39m, timer\u001b[39m=\u001b[39mdefault_timer,\n\u001b[1;32m    231\u001b[0m            number\u001b[39m=\u001b[39mdefault_number, \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    232\u001b[0m     \u001b[39m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     \u001b[39mreturn\u001b[39;00m Timer(stmt, setup, timer, \u001b[39mglobals\u001b[39;49m)\u001b[39m.\u001b[39;49mtimeit(number)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/timeit.py:177\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    175\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m    176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[1;32m    178\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<timeit-src>:6\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m~/gesture_progect/gesture_classification/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:447\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    449\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/gesture_progect/gesture_classification/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:430\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    427\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    429\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 430\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef_\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    431\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/gesture_progect/gesture_classification/env/lib/python3.9/site-packages/sklearn/utils/extmath.py:152\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m         ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(a, b)\n\u001b[1;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39;49m b\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    155\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[1;32m    156\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[1;32m    157\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[1;32m    158\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m ):\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LogReg(max_iter=1)\n",
    "print(model.name)\n",
    "print(model.main_dict)\n",
    "print()\n",
    "model.fit(data_tensor, y_train)\n",
    "preds = model.predict(data_tensor_test)\n",
    "print(accuracy_score(y_test, preds))\n",
    "print()\n",
    "model.eval_inference_time(data_tensor_test, 1000)\n",
    "print()\n",
    "accs = model.eval_model(data_tensor, y_train, data_tensor_test, y_test)\n",
    "print(accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_for_working(model, data_tensor, data_tensor_test, y_train, y_test, n_timeit=1000):\n",
    "    print(model.name)\n",
    "    print(model.main_dict)\n",
    "    print()\n",
    "    model.fit(data_tensor, y_train)\n",
    "    preds = model.predict(data_tensor_test)\n",
    "    print(accuracy_score(y_test, preds))\n",
    "    print()\n",
    "    model.eval_inference_time(data_tensor_test[0:1,:,:], n_timeit)\n",
    "    print()\n",
    "    accs = model.eval_model(data_tensor, y_train, data_tensor_test, y_test)\n",
    "    print(accs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model XGBoost is fitting...\n",
      "9.7624831199646 s passed\n",
      "0.7029940119760479\n"
     ]
    }
   ],
   "source": [
    "model = XGBoost(n_estimators=1,)\n",
    "model.fit(data_tensor, y_train)\n",
    "preds = model.predict(data_tensor_test)\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time evaluation for mocel XGBoost... n_timeit=1000\n",
      "Inference time for nodel XGBoost: 38.416 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.038415600760024975"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval_inference_time(data_tensor_test[0:1,:,:], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "{'name': 'XGBoost', 'do_scaler': False, 'n_trials': 10, 'params': {'n_estimators': 1}}\n",
      "\n",
      "Model XGBoost is fitting...\n",
      "11.604217767715454 s passed\n",
      "0.8911424903722721\n",
      "\n",
      "Inference time evaluation for mocel XGBoost... n_timeit=1000\n",
      "Inference time for nodel XGBoost: 41.286 ms\n",
      "\n",
      "Modle XGBoost is evaluating... n_trials=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:39<00:00,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean acc: 89.11(0.00)%\n",
      "Mean fitting times:9.846737575531005\n",
      "[0.89114249 0.89114249 0.89114249 0.89114249 0.89114249 0.89114249\n",
      " 0.89114249 0.89114249 0.89114249 0.89114249]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_model_for_working(SVMClassifier(n_estimators=1,), data_tensor[:,:,:], data_tensor[:,:,:], y_train[:], y_train[:], n_timeit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxIter  2\n",
      "ovr 1.0 1.0 2 0.01 l2 True 0.01 squared_hinge 100000\n",
      "STMM\n",
      "{'name': 'STMM', 'do_scaler': False, 'n_trials': 3, 'params': {}}\n",
      "\n",
      "STM reshape\n",
      "Model STMM is fitting...\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "0.3530268669128418 s passed\n",
      "STM reshape\n",
      "1.0\n",
      "\n",
      "Inference time evaluation for mocel STMM... n_timeit=10\n",
      "STM reshape\n",
      "Inference time for nodel STMM: 1.064 ms\n",
      "\n",
      "STM reshape\n",
      "STM reshape\n",
      "Modle STMM is evaluating... n_trials=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STM reshape\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "STM reshape\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "STM reshape\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "1 / 2\n",
      "2 / 2\n",
      "Mean acc: 100.00(0.00)%\n",
      "Mean fitting times:0.2322258154551188\n",
      "[1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_model_for_working(STMM(), data_tensor[:10,:,:], data_tensor[:10,:,:], y_train[:10], y_train[:10], n_timeit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time evaluation for mocel LogReg... n_timeit=100000\n",
      "Inference time for nodel LogReg: 0.389 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0003890264711994678"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval_inference_time(data_tensor_test[0:1,:,:], 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013584443819179327"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.22686021178029478 / data_tensor_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(data_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5095808383233533"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50958084, 0.50958084, 0.50958084, 0.50958084, 0.50958084])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modle LogReg is evaluating... n_trials=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/home/s.gostilovich/gesture_progect/gesture_classification/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 20%|██        | 1/5 [00:04<00:18,  4.56s/it]/home/s.gostilovich/gesture_progect/gesture_classification/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 40%|████      | 2/5 [00:08<00:12,  4.33s/it]/home/s.gostilovich/gesture_progect/gesture_classification/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 60%|██████    | 3/5 [00:13<00:08,  4.44s/it]/home/s.gostilovich/gesture_progect/gesture_classification/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 80%|████████  | 4/5 [00:17<00:04,  4.35s/it]/home/s.gostilovich/gesture_progect/gesture_classification/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 5/5 [00:22<00:00,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean acc: 50.96(0.00)%\n",
      "Mean fitting times:3.3809622287750245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accs = model.eval_model(data_tensor, y_train, data_tensor_test, y_test, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LogReg'>\n"
     ]
    }
   ],
   "source": [
    "print(LogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LogReg'>\n",
      "LogReg: {} was created\n"
     ]
    }
   ],
   "source": [
    "model = create_model({'model_type': 'LogReg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg: {}\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'params'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelAbstract.PARAMS_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelAbstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(init_model_dict):\n",
    "    model_type_str = init_model_dict['model_type']\n",
    "    \n",
    "    model_type = None\n",
    "    model_type = eval(model_type_str)\n",
    "    \n",
    "    print(model_type)\n",
    "    PARAMS_KEY = ModelAbstract.PARAMS_KEY\n",
    "    if PARAMS_KEY not in init_model_dict.keys():\n",
    "        init_model_dict[PARAMS_KEY] = {}\n",
    "        \n",
    "    model = model_type(**init_model_dict[PARAMS_KEY])\n",
    "    print(model, 'was created')\n",
    "    return model\n",
    "\n",
    "class ModelAbstract(ABC):\n",
    "    NAME_KEY = 'name'\n",
    "    DO_SCALER_KEY = 'do_scaler'\n",
    "    N_TRIALS_KEY = 'n_trials'\n",
    "    PARAMS_KEY = 'params'\n",
    "    ALL_PARAMS_KEY = 'all_params'\n",
    "    \n",
    "    def __init__(self, src=None, **kwargs):\n",
    "        self.main_dict = {self.NAME_KEY: None,\n",
    "                          self.DO_SCALER_KEY: False,\n",
    "                          self.N_TRIALS_KEY: 1,\n",
    "                          self.PARAMS_KEY: {},}\n",
    "        if src is not None:\n",
    "            self.load_model_dict(src)\n",
    "            \n",
    "        for key in kwargs.keys():\n",
    "            self.main_dict[self.PARAMS_KEY][key] = kwargs[key]\n",
    "            \n",
    "        self.model = self.init_model()  # with updating self.main_dict\n",
    "        \n",
    "        self.params = self.main_dict[self.PARAMS_KEY]\n",
    "        self.all_params = self.model.get_params()\n",
    "        \n",
    "        self.do_scaler = self.main_dict[self.DO_SCALER_KEY]\n",
    "        self.name = self.main_dict[self.NAME_KEY]\n",
    "        self.n_trials = self.main_dict[self.N_TRIALS_KEY]\n",
    "        self.scaler = None\n",
    "        \n",
    "        self.fit_time=None\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return self.name + \": \" + str(self.params)\n",
    "      \n",
    "             \n",
    "    # init methods \n",
    "    @abstractmethod\n",
    "    def init_model(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def gen_default_params(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def reshape_X_tensor(self, X_tensor):\n",
    "        if len(X_tensor.shape) > 2:\n",
    "            X_tensor = X_tensor.reshape(X_tensor.shape[0], -1)  \n",
    "        return X_tensor       \n",
    "    \n",
    "    def fit(self, X_train, y_train, verbose=1):\n",
    "        \n",
    "        X_train = self.reshape_X_tensor(X_train)\n",
    "        \n",
    "        if self.do_scaler:\n",
    "            self.scaler = StandardScaler().fit(X_train)\n",
    "            X_train = self.scaler.transform(X_train)\n",
    "          \n",
    "        if verbose > 0:  \n",
    "            print(f\"Model {self.name} is fitting...\")\n",
    "        t = time.time()\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.fit_time = (time.time() - t)\n",
    "        if verbose > 0:\n",
    "            print(f\"{self.fit_time} s passed\")\n",
    "        return self\n",
    "             \n",
    "    def predict(self, X):\n",
    "        X = self.reshape_X_tensor(X)\n",
    "        \n",
    "        if self.do_scaler:\n",
    "            X = self.scaler.transform(X)\n",
    "            \n",
    "        pred = self.model.predict(X)\n",
    "        return pred\n",
    "           \n",
    "    def eval_model(self, X_train, y_train, X_test, y_test, n_trials=None, metric_fun=accuracy_score, metric_name='acc', show_presentage=True):\n",
    "        \n",
    "        if n_trials is None:\n",
    "            n_trials = self.n_trials\n",
    "            \n",
    "        X_train = self.reshape_X_tensor(X_train)\n",
    "        X_test = self.reshape_X_tensor(X_test)\n",
    "        \n",
    "        if self.do_scaler:\n",
    "            X_train = self.scaler.transform(X_train)\n",
    "            X_test = self.scaler.transform(X_test)\n",
    "        \n",
    "        acc_array = []\n",
    "        fit_times = []\n",
    "        print(f\"Modle {self.name} is evaluating... n_trials={n_trials}\")\n",
    "        for i in tqdm(range(n_trials)): \n",
    "            \n",
    "            self.fit(X_train, y_train, verbose=0)\n",
    "            fit_times += [self.fit_time]    \n",
    "            pred = self.model.predict(X_test)\n",
    "            acc = metric_fun(y_test, pred)\n",
    "            acc_array += [acc]\n",
    "        acc_array = np.array(acc_array)\n",
    "        mean = acc_array.mean()\n",
    "        std = acc_array.std(ddof=1)\n",
    "        \n",
    "        show_str= f\"{mean:.4f}({std:.4f})\"\n",
    "        if show_presentage:\n",
    "            show_str= f\"{100*mean:.2f}({100*std:.2f})%\"\n",
    "\n",
    "        print(f\"Mean {metric_name}: {show_str}\" )\n",
    "        print(f\"Mean fitting times:{np.array(fit_times).mean()}\" )\n",
    "        return acc_array\n",
    "        \n",
    "        \n",
    "        \n",
    "    def eval_inference_time(self, X, n_timeit=100):\n",
    "        \n",
    "        print(f\"Inference time evaluation for mocel {self.name}... n_timeit={n_timeit}\")\n",
    "        X= self.reshape_X_tensor(X)\n",
    "        if self.do_scaler:\n",
    "            X = self.scaler.transform(X)\n",
    "            \n",
    "        # model = self\n",
    "        total_time = timeit.timeit('self.model.predict(X)', number=n_timeit, globals=locals())\n",
    "        inference_time = total_time/n_timeit\n",
    "        print(f\"Inference time for nodel {self.name}: {1000*inference_time:.3f} ms\")\n",
    "        return inference_time\n",
    "            \n",
    "  \n",
    "    def load_model_dict(self, src):\n",
    "        with open(src, 'r') as f:\n",
    "            main_dict = json.load(f)\n",
    "        for key in main_dict.keys():\n",
    "            self.main_dict[key] = main_dict[key]\n",
    "        return main_dict\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "     \n",
    "class LogReg(ModelAbstract):\n",
    "    def gen_default_params(self):\n",
    "        def_params = dict(n_jobs=-1)\n",
    "        return def_params\n",
    "        \n",
    "    def init_model(self):\n",
    "        self.main_dict[self.NAME_KEY] = 'LogReg'\n",
    "        self.main_dict[self.DO_SCALER_KEY] = True\n",
    "        self.main_dict[self.N_TRIALS_KEY] = 3\n",
    "                \n",
    "        params = self.gen_default_params()\n",
    "        params_new = self.main_dict[self.PARAMS_KEY]\n",
    "        for key in params_new.keys():\n",
    "            params[key] = params_new[key]\n",
    "        \n",
    "        return LogisticRegression(**params)\n",
    "\n",
    "  \n",
    "class RandForest(ModelAbstract):\n",
    "    def gen_default_params(self):\n",
    "        def_params = dict(n_jobs=-1)\n",
    "        return def_params\n",
    "        \n",
    "    def init_model(self):\n",
    "        self.main_dict[self.NAME_KEY] = 'RandForest'\n",
    "        self.main_dict[self.DO_SCALER_KEY] = False\n",
    "        self.main_dict[self.N_TRIALS_KEY] = 10\n",
    "                \n",
    "        params = self.gen_default_params()\n",
    "        params_new = self.main_dict[self.PARAMS_KEY]\n",
    "        for key in params_new.keys():\n",
    "            params[key] = params_new[key]\n",
    "        \n",
    "        return RandomForestClassifier(**params)\n",
    "    \n",
    "    \n",
    "class XGBoost(ModelAbstract):\n",
    "    def gen_default_params(self):\n",
    "        def_params = dict(n_jobs=-1)\n",
    "        return def_params\n",
    "        \n",
    "    def init_model(self):\n",
    "        self.main_dict[self.NAME_KEY] = 'XGBoost'\n",
    "        self.main_dict[self.DO_SCALER_KEY] = False\n",
    "        self.main_dict[self.N_TRIALS_KEY] = 10\n",
    "                \n",
    "        params = self.gen_default_params()\n",
    "        params_new = self.main_dict[self.PARAMS_KEY]\n",
    "        for key in params_new.keys():\n",
    "            params[key] = params_new[key]\n",
    "        \n",
    "        return xgb.XGBClassifier(**params)\n",
    "  \n",
    "    \n",
    "class SVMClassifier(ModelAbstract):\n",
    "    def gen_default_params(self):\n",
    "        def_params = dict(kernel='linear')\n",
    "        return def_params\n",
    "        \n",
    "    def init_model(self):\n",
    "        self.main_dict[self.NAME_KEY] = 'SVMClassifier'\n",
    "        self.main_dict[self.DO_SCALER_KEY] = True\n",
    "        self.main_dict[self.N_TRIALS_KEY] = 10\n",
    "                \n",
    "        params = self.gen_default_params()\n",
    "        params_new = self.main_dict[self.PARAMS_KEY]\n",
    "        for key in params_new.keys():\n",
    "            params[key] = params_new[key]\n",
    "        \n",
    "        return SVC(**params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class STMM(ModelAbstract):\n",
    "    def reshape_X_tensor(self, X_tensor):\n",
    "        print('STM reshape')\n",
    "        if len(X_tensor.shape) < 3:\n",
    "            X_tensor = X_tensor.reshape(list(X_tensor.shape) + [-1]) \n",
    "        return X_tensor\n",
    "    \n",
    "    def gen_default_params(self):\n",
    "        def_params = dict(maxIter=2, tolSTM=1e-2, tol=1e-2)\n",
    "        return def_params\n",
    "        \n",
    "    def init_model(self):\n",
    "        self.main_dict[self.NAME_KEY] = 'STMM'\n",
    "        self.main_dict[self.DO_SCALER_KEY] = False\n",
    "        self.main_dict[self.N_TRIALS_KEY] = 3\n",
    "                \n",
    "        params = self.gen_default_params()\n",
    "        params_new = self.main_dict[self.PARAMS_KEY]\n",
    "        for key in params_new.keys():\n",
    "            params[key] = params_new[key]\n",
    "        \n",
    "        return pystmm.classifier.STMM(**params)\n",
    "        \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modlel = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56f519b09a7c96e87057d7f72b4f85aa2fa44db40cb4e1ff2739da3af976aad2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
